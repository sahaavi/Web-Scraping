{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the reasons why we have to learn selenium is because it allows us to scrape JavaScript driven websites, with this we'll be able to script websites with dynamic content.  \n",
    "How to identify if a website was buit with JavaScript?\n",
    "> Inspect the webpage in browser  \n",
    "<img src=\"../images/inspect.png\"  width=\"60%\" height=\"30%\">  \n",
    "Then go to the settings  \n",
    "<img src=\"../images/settings.png\"  width=\"60%\" height=\"30%\">  \n",
    "Find the `Debugger` option in settings and turn on the `Disable JavaScript` option.  \n",
    "<img src=\"../images/disable_JS.png\"  width=\"60%\" height=\"30%\">  \n",
    "Now reload the webpage. If the webpage doesn't reload or does not contain all the data like before that means the website built with JavaScript.  \n",
    "<img src=\"../images/load_error.png\"  width=\"60%\" height=\"30%\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download ChromeDriver according to your Google Chrome browser version. [ChromeDriver](https://chromedriver.chromium.org/downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# setup chrome driver\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "# website to scrape\n",
    "# website = \"https://www.adamchoi.co.uk/overs/detailed\"\n",
    "\n",
    "from selenium import webdriver\n",
    "website = \"https://www.adamchoi.co.uk/overs/detailed\" # website to scrape\n",
    "path = \"C:/chromedriver_win32/chromedriver.exe\" # path to chromedriver.exe\n",
    "driver = webdriver.Chrome(path) # setup chrome driver\n",
    "driver.get(website) # open website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit() # close chrome driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find element by id  `driver.find_element_by_id('id')`  \n",
    "Find element by class name `driver.find_element_by_class_name('class_name')`  \n",
    "Find element by tag name `driver.find_element_by_tag_name('tag')`. This is frequently used when you want to locate multiple elements with the same tag name.   \n",
    "Find element by XPath `driver.find_element_by_xpath('//tag[@AttributeName=\"Value\"]')`  \n",
    "Find element by CSS Selector `driver.find_element_by_css_selector()`  \n",
    "Find element by name `driver.find_element_by_name()`  \n",
    "Find element by link text `driver.find_element_by_link_text()`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to find elemnets instead of a single element, put a s after element in the function name.  \n",
    "For ex. `driver.find_elements_by_class_name('class_name')`  \n",
    "This will return a list of all the elements of given class_name whereas `find_element` will return only one element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things you can locate with selenium are dropdowns, also can choose any element listed in a dropdown. Also can `Login` to websites and scrape dynamic websites using `Waits`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate any element in Browser using XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the .py file for this [here](https://github.com/sahaavi/Web-Scraping/blob/main/Selenium/argentina_matches.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape data from table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going into the inspect option, use `ctrl+F` to open the XPath input field.  \n",
    "![xpath field in browser](../images/xpath.png)\n",
    "<!-- <img src=\"https://github.com/sahaavi/Web-Scraping/blob/main/images/xpath.png\"> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "website = \"https://www.adamchoi.co.uk/overs/detailed\" # website to scrape\n",
    "path = \"C:/chromedriver_win32/chromedriver.exe\" # path to chromedriver.exe\n",
    "driver = webdriver.Chrome(path) # setup chrome driver\n",
    "driver.get(website) # open website\n",
    "\n",
    "# Add implicit wait\n",
    "driver.implicitly_wait(10)  # Wait up to 10 seconds for elements to be found\n",
    "\n",
    "# remember if you use single quotes inside for attribute value, use double quotes outside for the whole xpath or vice versa\n",
    "all_matches_button = driver.find_element_by_xpath(\"//label[@analytics-event='All matches']\") # find element by xpath\n",
    "all_matches_button.click() # click on the element\n",
    "\n",
    "matches = driver.find_elements_by_tag_name('tr') # find all elements by tr tag name \n",
    "\n",
    "for match in matches: # loop through all matches\n",
    "    print(match.text) # print text of each match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will store each row information in one cell but we want to make them seperate. To get each column seperately inside a row we can use XPath.  \n",
    "![column](../images/column.png)\n",
    "<!-- <img src=\"https://github.com/sahaavi/Web-Scraping/blob/main/images/column.png\"> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store scraped data in lists\n",
    "date = []\n",
    "home_team = []\n",
    "score = []\n",
    "away_team = []\n",
    "\n",
    "for match in matches: # loop through all matches\n",
    "    date.append(match.find_element_by_xpath('./td[1]').text)\n",
    "    home_team.append(match.find_element_by_xpath('./td[2]').text)\n",
    "    score.append(match.find_element_by_xpath('./td[3]').text)\n",
    "    away_team.append(match.find_element_by_xpath('./td[4]').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit() # close chrome driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Dropdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dropdown is dynamic (built with AJAX), means when you choose different option from dropdown the website link won't change, only the data of page will change, then we have to use `Select()` function in selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "dropdown = Select(driver.find_element_by_id('country')) # find dropdown element by id\n",
    "dropdown.select_by_visible_text('Argentina') # select dropdown option by visible text\n",
    "\n",
    "# in the actual website when you change the dropdown option, the table is updated after a few seconds\n",
    "# so we need to wait for the table to be updated before we scrape the data\n",
    "# otherwise code can break if we try to scrape the data before it is updated\n",
    "# we can use time.sleep() to wait for a few seconds \n",
    "# but we can also use driver.implicitly_wait()\n",
    "import time\n",
    "time.sleep(5) # wait 5 seconds for elements to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dropdown selection in action [here](https://github.com/sahaavi/Web-Scraping/blob/main/Selenium/argentina_matches.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check how to handle pagination with Selenium and built an Amazon Audible Bot [here](https://github.com/sahaavi/Web-Scraping/blob/main/Selenium/audible_bot.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Headless Mode` on Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headless mode is an option that Selenium has that let us run the bot we create on the background.  \n",
    "This is useful when you're doing other tasks and you don't want to see that browser opening over and over again every time selenium is scraping the website so you can let the machine do the job silently on the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `Headless Audible Bot` in action [here](https://github.com/sahaavi/Web-Scraping/blob/main/Selenium/headless_audible_bot.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
